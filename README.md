We propose the development of a search engine that introduces a novel AI-driven truth and reliability scoring system, assigning each search result a truth parameter on a scale of 0 (lie) to 10 (absolute truth). 
Drawing on methodologies from recent AI research, such as those in https://arxiv.org/abs/2407.12831, 
and inspired by the need to combat misinformation, this approach redefines search engines by providing users with a quantifiable measure of information trustworthiness.

Each search result displays a colored gauge indicating its truthfulness—green for high reliability and red for low—making it easy to assess credibility at a glance. 
Users can sort results by this truth parameter or apply a filter to prioritize the most trustworthy information. 
A hoverable icon next to each score provides a brief explanation of the AI’s analysis, adding transparency. 
The interface adopts a clean, academic design with a prominent search bar, ensuring clarity and ease of use while reinforcing the focus on truth and reliability.

Our model is publicly available at https://huggingface.co/JoydeepC/TrueGL_Granite/tree/main

Note that the project is created for educational and research purposes only and is not intended for commercial use. The data used for training and fine-tuning the AI models is either collected from open-sources or AI-generated and is not collected or used in any way that violates privacy or ethical guidelines.

We are always looking for the motivated collaborators to join us in this exciting project. If you are interested in contributing to the development of this search engine, please feel free to reach out to us at algazinovalexandr@gmail.com.
